{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\emili\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import tflearn.datasets.oxflower17 as oxflower17\n",
    "X, Y = oxflower17.load_data(one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(96, kernel_size=(11, 11), strides=(4, 4), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(384, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(384, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(17, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 54, 54, 96)        34944     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 26, 26, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 26, 26, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 22, 22, 256)       614656    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 10, 10, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 10, 10, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 6, 6, 384)         885120    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 384)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1, 1, 384)         1536      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              1576960   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 17)                69649     \n",
      "=================================================================\n",
      "Total params: 21,883,153\n",
      "Trainable params: 21,881,681\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1224 samples, validate on 136 samples\n",
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "Epoch 1/100\n",
      "1224/1224 [==============================] - ETA: 0s - loss: 4.5348 - acc: 0.2394WARNING:tensorflow:From c:\\users\\emili\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py:2048: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "1224/1224 [==============================] - 1s 923us/sample - loss: 4.5348 - acc: 0.2394 - val_loss: 8.3329 - val_acc: 0.1397\n",
      "Epoch 2/100\n",
      "1224/1224 [==============================] - 1s 756us/sample - loss: 3.3187 - acc: 0.3023 - val_loss: 4.7953 - val_acc: 0.0882\n",
      "Epoch 3/100\n",
      "1224/1224 [==============================] - 1s 739us/sample - loss: 2.5226 - acc: 0.3913 - val_loss: 5.3711 - val_acc: 0.1544\n",
      "Epoch 4/100\n",
      "1224/1224 [==============================] - 1s 722us/sample - loss: 2.2958 - acc: 0.4085 - val_loss: 4.8149 - val_acc: 0.1250\n",
      "Epoch 5/100\n",
      "1224/1224 [==============================] - 1s 709us/sample - loss: 2.3232 - acc: 0.4281 - val_loss: 4.7343 - val_acc: 0.1912\n",
      "Epoch 6/100\n",
      "1224/1224 [==============================] - 1s 704us/sample - loss: 2.4443 - acc: 0.4183 - val_loss: 2.2305 - val_acc: 0.3824\n",
      "Epoch 7/100\n",
      "1224/1224 [==============================] - 1s 711us/sample - loss: 2.1273 - acc: 0.4649 - val_loss: 3.6431 - val_acc: 0.2353\n",
      "Epoch 8/100\n",
      "1224/1224 [==============================] - 1s 746us/sample - loss: 1.8873 - acc: 0.5057 - val_loss: 3.1519 - val_acc: 0.2868\n",
      "Epoch 9/100\n",
      "1224/1224 [==============================] - 1s 787us/sample - loss: 1.9056 - acc: 0.4926 - val_loss: 2.8696 - val_acc: 0.3897\n",
      "Epoch 10/100\n",
      "1224/1224 [==============================] - 1s 766us/sample - loss: 1.9735 - acc: 0.5114 - val_loss: 3.3622 - val_acc: 0.3382\n",
      "Epoch 11/100\n",
      "1224/1224 [==============================] - 1s 753us/sample - loss: 1.8353 - acc: 0.5016 - val_loss: 2.8393 - val_acc: 0.3603\n",
      "Epoch 12/100\n",
      "1224/1224 [==============================] - 1s 739us/sample - loss: 1.8585 - acc: 0.5310 - val_loss: 2.0324 - val_acc: 0.4338\n",
      "Epoch 13/100\n",
      "1224/1224 [==============================] - 1s 763us/sample - loss: 1.5209 - acc: 0.5662 - val_loss: 2.2814 - val_acc: 0.4265\n",
      "Epoch 14/100\n",
      "1224/1224 [==============================] - 1s 810us/sample - loss: 1.4756 - acc: 0.6013 - val_loss: 2.5336 - val_acc: 0.3971\n",
      "Epoch 15/100\n",
      "1224/1224 [==============================] - 1s 770us/sample - loss: 1.3991 - acc: 0.5874 - val_loss: 3.4098 - val_acc: 0.3456\n",
      "Epoch 16/100\n",
      "1224/1224 [==============================] - 1s 697us/sample - loss: 1.3784 - acc: 0.6283 - val_loss: 2.8658 - val_acc: 0.4485\n",
      "Epoch 17/100\n",
      "1224/1224 [==============================] - 1s 720us/sample - loss: 1.1549 - acc: 0.6544 - val_loss: 1.8047 - val_acc: 0.5515\n",
      "Epoch 18/100\n",
      "1224/1224 [==============================] - 1s 734us/sample - loss: 1.2341 - acc: 0.6593 - val_loss: 2.9060 - val_acc: 0.3750\n",
      "Epoch 19/100\n",
      "1224/1224 [==============================] - 1s 702us/sample - loss: 1.2879 - acc: 0.6569 - val_loss: 2.4493 - val_acc: 0.4926\n",
      "Epoch 20/100\n",
      "1224/1224 [==============================] - 1s 775us/sample - loss: 1.2908 - acc: 0.6569 - val_loss: 1.9058 - val_acc: 0.5221\n",
      "Epoch 21/100\n",
      "1224/1224 [==============================] - 1s 773us/sample - loss: 1.3436 - acc: 0.6422 - val_loss: 2.1273 - val_acc: 0.5588\n",
      "Epoch 22/100\n",
      "1224/1224 [==============================] - 1s 771us/sample - loss: 1.2677 - acc: 0.6683 - val_loss: 2.3304 - val_acc: 0.4926\n",
      "Epoch 23/100\n",
      "1224/1224 [==============================] - 1s 766us/sample - loss: 1.3509 - acc: 0.6503 - val_loss: 3.4228 - val_acc: 0.3897\n",
      "Epoch 24/100\n",
      "1224/1224 [==============================] - 1s 758us/sample - loss: 1.1924 - acc: 0.6887 - val_loss: 4.2491 - val_acc: 0.3750\n",
      "Epoch 25/100\n",
      "1224/1224 [==============================] - 1s 763us/sample - loss: 1.0459 - acc: 0.6969 - val_loss: 4.3689 - val_acc: 0.3456\n",
      "Epoch 26/100\n",
      "1224/1224 [==============================] - 1s 747us/sample - loss: 1.1650 - acc: 0.6961 - val_loss: 3.6546 - val_acc: 0.3824\n",
      "Epoch 27/100\n",
      "1224/1224 [==============================] - 1s 762us/sample - loss: 1.0186 - acc: 0.7451 - val_loss: 3.0242 - val_acc: 0.4926\n",
      "Epoch 28/100\n",
      "1224/1224 [==============================] - 1s 732us/sample - loss: 0.7114 - acc: 0.7859 - val_loss: 1.9467 - val_acc: 0.6103\n",
      "Epoch 29/100\n",
      "1224/1224 [==============================] - 1s 760us/sample - loss: 0.8216 - acc: 0.7933 - val_loss: 3.1766 - val_acc: 0.5368\n",
      "Epoch 30/100\n",
      "1224/1224 [==============================] - 1s 770us/sample - loss: 0.6075 - acc: 0.8178 - val_loss: 1.9945 - val_acc: 0.5809\n",
      "Epoch 31/100\n",
      "1224/1224 [==============================] - 1s 757us/sample - loss: 0.7615 - acc: 0.7851 - val_loss: 3.1387 - val_acc: 0.5074\n",
      "Epoch 32/100\n",
      "1224/1224 [==============================] - 1s 761us/sample - loss: 0.5815 - acc: 0.8252 - val_loss: 3.2263 - val_acc: 0.5441\n",
      "Epoch 33/100\n",
      "1224/1224 [==============================] - 1s 753us/sample - loss: 0.4806 - acc: 0.8562 - val_loss: 1.8682 - val_acc: 0.6544\n",
      "Epoch 34/100\n",
      "1224/1224 [==============================] - 1s 760us/sample - loss: 0.4149 - acc: 0.8685 - val_loss: 2.9244 - val_acc: 0.5588\n",
      "Epoch 35/100\n",
      "1224/1224 [==============================] - 1s 753us/sample - loss: 1.2224 - acc: 0.7075 - val_loss: 3.5984 - val_acc: 0.3309\n",
      "Epoch 36/100\n",
      "1224/1224 [==============================] - 1s 772us/sample - loss: 1.2968 - acc: 0.6814 - val_loss: 2.5032 - val_acc: 0.5441\n",
      "Epoch 37/100\n",
      "1224/1224 [==============================] - 1s 737us/sample - loss: 1.2690 - acc: 0.7010 - val_loss: 2.9877 - val_acc: 0.4265\n",
      "Epoch 38/100\n",
      "1224/1224 [==============================] - 1s 778us/sample - loss: 1.1130 - acc: 0.7255 - val_loss: 2.7404 - val_acc: 0.4926\n",
      "Epoch 39/100\n",
      "1224/1224 [==============================] - 1s 769us/sample - loss: 0.7054 - acc: 0.7974 - val_loss: 2.5280 - val_acc: 0.5221\n",
      "Epoch 40/100\n",
      "1224/1224 [==============================] - 1s 760us/sample - loss: 0.6635 - acc: 0.7998 - val_loss: 1.9377 - val_acc: 0.6765\n",
      "Epoch 41/100\n",
      "1224/1224 [==============================] - 1s 752us/sample - loss: 0.5803 - acc: 0.8358 - val_loss: 2.3122 - val_acc: 0.5809\n",
      "Epoch 42/100\n",
      "1224/1224 [==============================] - 1s 755us/sample - loss: 0.4999 - acc: 0.8570 - val_loss: 1.8783 - val_acc: 0.6618\n",
      "Epoch 43/100\n",
      "1224/1224 [==============================] - 1s 752us/sample - loss: 0.4660 - acc: 0.8652 - val_loss: 2.6167 - val_acc: 0.5735\n",
      "Epoch 44/100\n",
      "1224/1224 [==============================] - 1s 759us/sample - loss: 0.6332 - acc: 0.8423 - val_loss: 2.5562 - val_acc: 0.5515\n",
      "Epoch 45/100\n",
      "1224/1224 [==============================] - 1s 753us/sample - loss: 0.4163 - acc: 0.8873 - val_loss: 3.8661 - val_acc: 0.4632\n",
      "Epoch 46/100\n",
      "1224/1224 [==============================] - 1s 755us/sample - loss: 0.8738 - acc: 0.8023 - val_loss: 2.1372 - val_acc: 0.6029\n",
      "Epoch 47/100\n",
      "1224/1224 [==============================] - 1s 730us/sample - loss: 0.5996 - acc: 0.8464 - val_loss: 3.4114 - val_acc: 0.4779\n",
      "Epoch 48/100\n",
      "1224/1224 [==============================] - 1s 765us/sample - loss: 0.5956 - acc: 0.8464 - val_loss: 3.2715 - val_acc: 0.5000\n",
      "Epoch 49/100\n",
      "1224/1224 [==============================] - 1s 800us/sample - loss: 0.4394 - acc: 0.8709 - val_loss: 2.9148 - val_acc: 0.5368\n",
      "Epoch 50/100\n",
      "1224/1224 [==============================] - 1s 713us/sample - loss: 0.3315 - acc: 0.8971 - val_loss: 2.5553 - val_acc: 0.5662\n",
      "Epoch 51/100\n",
      "1224/1224 [==============================] - 1s 702us/sample - loss: 0.2712 - acc: 0.9175 - val_loss: 2.4232 - val_acc: 0.5956\n",
      "Epoch 52/100\n",
      "1224/1224 [==============================] - 1s 729us/sample - loss: 0.2643 - acc: 0.9199 - val_loss: 4.1541 - val_acc: 0.4706\n",
      "Epoch 53/100\n",
      "1224/1224 [==============================] - 1s 717us/sample - loss: 0.2695 - acc: 0.9158 - val_loss: 2.2603 - val_acc: 0.6618\n",
      "Epoch 54/100\n",
      "1224/1224 [==============================] - 1s 712us/sample - loss: 0.4861 - acc: 0.8766 - val_loss: 2.5273 - val_acc: 0.6103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "1224/1224 [==============================] - 1s 783us/sample - loss: 0.3076 - acc: 0.9109 - val_loss: 2.1700 - val_acc: 0.6397\n",
      "Epoch 56/100\n",
      "1224/1224 [==============================] - 1s 778us/sample - loss: 0.6752 - acc: 0.8652 - val_loss: 2.6376 - val_acc: 0.5441\n",
      "Epoch 57/100\n",
      "1224/1224 [==============================] - 1s 795us/sample - loss: 0.5433 - acc: 0.8709 - val_loss: 2.8565 - val_acc: 0.5515\n",
      "Epoch 58/100\n",
      "1224/1224 [==============================] - 1s 764us/sample - loss: 0.7470 - acc: 0.8211 - val_loss: 3.5319 - val_acc: 0.4926\n",
      "Epoch 59/100\n",
      "1224/1224 [==============================] - 1s 756us/sample - loss: 0.5913 - acc: 0.8391 - val_loss: 2.6218 - val_acc: 0.6029\n",
      "Epoch 60/100\n",
      "1224/1224 [==============================] - 1s 747us/sample - loss: 0.4323 - acc: 0.8881 - val_loss: 2.8911 - val_acc: 0.5809\n",
      "Epoch 61/100\n",
      "1224/1224 [==============================] - 1s 760us/sample - loss: 0.4204 - acc: 0.8864 - val_loss: 2.4731 - val_acc: 0.6912\n",
      "Epoch 62/100\n",
      "1224/1224 [==============================] - 1s 765us/sample - loss: 0.7613 - acc: 0.8243 - val_loss: 3.7724 - val_acc: 0.5515\n",
      "Epoch 63/100\n",
      "1224/1224 [==============================] - 1s 752us/sample - loss: 0.5518 - acc: 0.8554 - val_loss: 3.2593 - val_acc: 0.5515\n",
      "Epoch 64/100\n",
      "1224/1224 [==============================] - 1s 763us/sample - loss: 0.4044 - acc: 0.8905 - val_loss: 4.2959 - val_acc: 0.4853\n",
      "Epoch 65/100\n",
      "1224/1224 [==============================] - 1s 759us/sample - loss: 0.2844 - acc: 0.9142 - val_loss: 2.8821 - val_acc: 0.6250\n",
      "Epoch 66/100\n",
      "1224/1224 [==============================] - 1s 753us/sample - loss: 0.5751 - acc: 0.8750 - val_loss: 3.7346 - val_acc: 0.5000\n",
      "Epoch 67/100\n",
      "1224/1224 [==============================] - 1s 766us/sample - loss: 0.2758 - acc: 0.9240 - val_loss: 3.0519 - val_acc: 0.5809\n",
      "Epoch 68/100\n",
      "1224/1224 [==============================] - 1s 783us/sample - loss: 0.2357 - acc: 0.9379 - val_loss: 2.8934 - val_acc: 0.5956\n",
      "Epoch 69/100\n",
      "1224/1224 [==============================] - 1s 805us/sample - loss: 0.1990 - acc: 0.9436 - val_loss: 2.5689 - val_acc: 0.5735\n",
      "Epoch 70/100\n",
      "1224/1224 [==============================] - 1s 791us/sample - loss: 0.3332 - acc: 0.9216 - val_loss: 2.2226 - val_acc: 0.6397\n",
      "Epoch 71/100\n",
      "1224/1224 [==============================] - 1s 820us/sample - loss: 0.4375 - acc: 0.9028 - val_loss: 3.3517 - val_acc: 0.5882\n",
      "Epoch 72/100\n",
      "1224/1224 [==============================] - 1s 769us/sample - loss: 0.2039 - acc: 0.9493 - val_loss: 2.4956 - val_acc: 0.6397\n",
      "Epoch 73/100\n",
      "1224/1224 [==============================] - 1s 760us/sample - loss: 0.2785 - acc: 0.9191 - val_loss: 3.2693 - val_acc: 0.6029\n",
      "Epoch 74/100\n",
      "1224/1224 [==============================] - 1s 779us/sample - loss: 0.2032 - acc: 0.9379 - val_loss: 2.5580 - val_acc: 0.6324\n",
      "Epoch 75/100\n",
      "1224/1224 [==============================] - 1s 801us/sample - loss: 0.2246 - acc: 0.9493 - val_loss: 2.5098 - val_acc: 0.6544\n",
      "Epoch 76/100\n",
      "1224/1224 [==============================] - 1s 817us/sample - loss: 0.2973 - acc: 0.9379 - val_loss: 2.8143 - val_acc: 0.6324\n",
      "Epoch 77/100\n",
      "1224/1224 [==============================] - 1s 821us/sample - loss: 0.1954 - acc: 0.9477 - val_loss: 2.9090 - val_acc: 0.5882\n",
      "Epoch 78/100\n",
      "1224/1224 [==============================] - 1s 819us/sample - loss: 0.2811 - acc: 0.9265 - val_loss: 3.3380 - val_acc: 0.5882\n",
      "Epoch 79/100\n",
      "1224/1224 [==============================] - 1s 813us/sample - loss: 0.2018 - acc: 0.9493 - val_loss: 2.3322 - val_acc: 0.6691\n",
      "Epoch 80/100\n",
      "1224/1224 [==============================] - 1s 739us/sample - loss: 0.1175 - acc: 0.9608 - val_loss: 2.1948 - val_acc: 0.7059\n",
      "Epoch 81/100\n",
      "1224/1224 [==============================] - 1s 726us/sample - loss: 0.2621 - acc: 0.9428 - val_loss: 3.6038 - val_acc: 0.5882\n",
      "Epoch 82/100\n",
      "1224/1224 [==============================] - 1s 781us/sample - loss: 0.1609 - acc: 0.9592 - val_loss: 2.8026 - val_acc: 0.6471\n",
      "Epoch 83/100\n",
      "1224/1224 [==============================] - 1s 819us/sample - loss: 0.4047 - acc: 0.9060 - val_loss: 3.0118 - val_acc: 0.6397\n",
      "Epoch 84/100\n",
      "1224/1224 [==============================] - 1s 785us/sample - loss: 0.2972 - acc: 0.9248 - val_loss: 3.1317 - val_acc: 0.6176\n",
      "Epoch 85/100\n",
      "1224/1224 [==============================] - 1s 727us/sample - loss: 0.3434 - acc: 0.9191 - val_loss: 3.5359 - val_acc: 0.5588\n",
      "Epoch 86/100\n",
      "1224/1224 [==============================] - 1s 729us/sample - loss: 0.1709 - acc: 0.9542 - val_loss: 3.0468 - val_acc: 0.6250\n",
      "Epoch 87/100\n",
      "1224/1224 [==============================] - 1s 757us/sample - loss: 0.0862 - acc: 0.9714 - val_loss: 2.7221 - val_acc: 0.6691\n",
      "Epoch 88/100\n",
      "1224/1224 [==============================] - 1s 727us/sample - loss: 0.1052 - acc: 0.9730 - val_loss: 1.9972 - val_acc: 0.7353\n",
      "Epoch 89/100\n",
      "1224/1224 [==============================] - 1s 774us/sample - loss: 0.0526 - acc: 0.9837 - val_loss: 2.4190 - val_acc: 0.7059\n",
      "Epoch 90/100\n",
      "1224/1224 [==============================] - 1s 749us/sample - loss: 0.3555 - acc: 0.9395 - val_loss: 2.9392 - val_acc: 0.6838\n",
      "Epoch 91/100\n",
      "1224/1224 [==============================] - 1s 738us/sample - loss: 0.1607 - acc: 0.9600 - val_loss: 2.1981 - val_acc: 0.7059\n",
      "Epoch 92/100\n",
      "1224/1224 [==============================] - 1s 732us/sample - loss: 0.5657 - acc: 0.8815 - val_loss: 3.8172 - val_acc: 0.52210s - loss: 0.5858 - acc: 0.87\n",
      "Epoch 93/100\n",
      "1224/1224 [==============================] - 1s 757us/sample - loss: 0.5279 - acc: 0.8905 - val_loss: 3.6431 - val_acc: 0.5515\n",
      "Epoch 94/100\n",
      "1224/1224 [==============================] - 1s 711us/sample - loss: 0.5421 - acc: 0.8824 - val_loss: 3.6112 - val_acc: 0.5368\n",
      "Epoch 95/100\n",
      "1224/1224 [==============================] - 1s 766us/sample - loss: 0.3071 - acc: 0.9297 - val_loss: 3.0346 - val_acc: 0.6544\n",
      "Epoch 96/100\n",
      "1224/1224 [==============================] - 1s 728us/sample - loss: 0.2874 - acc: 0.9240 - val_loss: 3.0880 - val_acc: 0.6103\n",
      "Epoch 97/100\n",
      "1224/1224 [==============================] - 1s 758us/sample - loss: 0.1675 - acc: 0.9567 - val_loss: 2.5227 - val_acc: 0.6544\n",
      "Epoch 98/100\n",
      "1224/1224 [==============================] - 1s 729us/sample - loss: 0.2168 - acc: 0.9477 - val_loss: 2.5411 - val_acc: 0.5956\n",
      "Epoch 99/100\n",
      "1224/1224 [==============================] - 1s 732us/sample - loss: 0.1460 - acc: 0.9583 - val_loss: 3.3308 - val_acc: 0.5882\n",
      "Epoch 100/100\n",
      "1224/1224 [==============================] - 1s 738us/sample - loss: 0.3029 - acc: 0.9273 - val_loss: 3.7128 - val_acc: 0.6029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2f2797db7c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, batch_size=64, epochs=100, verbose=1, validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
